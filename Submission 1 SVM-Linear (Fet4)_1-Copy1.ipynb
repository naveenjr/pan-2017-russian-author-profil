{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XmlParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(file_name):\n",
    "    SumAccum = 0\n",
    "    filtered = ''.join(filter(lambda x: x not in '\".,;!-\\n',file_name))\n",
    "    for ch in filtered.split():\n",
    "        character = len(ch)\n",
    "        SumAccum = SumAccum + character\n",
    "    average = (SumAccum) /(float) (len(filtered.split()))\n",
    "    average=round(average)\n",
    "    return average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "from xml.dom.minidom import parse\n",
    "import xml.dom.minidom\n",
    "\n",
    "def get_data(dataFolder, testFile):\n",
    "    global urlcount,avg_nowords\n",
    "    xmlFile = os.path.join(dataFolder, testFile)\n",
    "    ## creating document object model from the xml file\n",
    "    DOMTree = xml.dom.minidom.parse(xmlFile)\n",
    "    collection = DOMTree.documentElement\n",
    "    ## getting author ID of the xml file \n",
    "    authorID = testFile.replace('.xml', '')\n",
    "    ## getting language of the xml file \n",
    "    Language = collection.getAttribute(\"lang\")\n",
    "    ## getting data in the xml file\n",
    "    Documents = collection.getElementsByTagName(\"document\")\n",
    "    Data = []\n",
    "    for Document in Documents:\n",
    "        if len(Document.childNodes) > 0:\n",
    "            Data.append(Document.childNodes[0].data.encode('utf-8'))\n",
    "            Datastr= ''.join(Data)\n",
    "            #urlcount=Datastr.count('http')\n",
    "            data1 = re.sub(r'/\\S+','https',(' '.join(map(str,(Datastr.split('http://t.co'))))))\n",
    "            data = re.sub(r'http\\S+','https',data1)\n",
    "            data = re.sub(r'@\\S+','@',data)\n",
    "            data=re.sub(r'#\\S+','#',data)\n",
    "            data=re.sub(r'\\.+', \". \", data)\n",
    "            data=re.sub(r'\\!+', \". \", data)\n",
    "            data = re.sub(r'-',r'',data)\n",
    "            data =data.lower()\n",
    "            #data = re.sub(r'[:)|;|,|!|?|*]',r'',data)\n",
    "            Data= re.sub(r'\\xf0\\x9f\\S+','emoji',data)\n",
    "            avg_nowords=avg(Data)\n",
    "        else:\n",
    "            Data.append(' ')\n",
    "    return Data, Language, authorID, avg_nowords#, urlcount,atcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataFolder, Action):\n",
    "    truthFilePath = os.path.join(dataFolder, 'truth.txt')\n",
    "    \n",
    "    '''specific for training data '''\n",
    "    genderList = []     ## creating empty list for appending gender class information\n",
    "    languageList = []   ## creating empty list for appending language of the xml file  \n",
    "    authorIDList = []   ## creating empty list for appending author ID of the xml file\n",
    "    authorTextList = [] ## creating empty list for appending author's tweets from the xml file \n",
    "    avglist=[]\n",
    "    # httpList = []\n",
    "    \n",
    "    if Action == 'TRAIN':   ## loop for loading training data\n",
    "        File = open(truthFilePath, 'r+') ## reading truth file\n",
    "        Text = File.read()\n",
    "        File.close()\n",
    "        truthTexts = Text.split('\\n')\n",
    "        for truthText in truthTexts: ## loop for loading tweets of the author and classes from the xml files in the truth file\n",
    "            truthText = truthText.split(':::')\n",
    "            if len(truthText) == 2:\n",
    "                xmlFile = truthText[0] + '.xml'\n",
    "                Data, Language, authorID,avg_nowords = get_data(dataFolder, xmlFile)\n",
    "                genderList.append(truthText[1])\n",
    "                authorTextList.append(Data)\n",
    "                languageList.append(Language)\n",
    "                #httpList.append(urlcount)\n",
    "                authorIDList.append(authorID)\n",
    "                avglist.append(avg_nowords)\n",
    "            else:\n",
    "                pass\n",
    "    else:                          ## loop for loading test data\n",
    "        xmlFiles = os.listdir(dataFolder)\n",
    "        for xmlFile in xmlFiles:   ## loop for loading tweets of the author from the xml files in the data folder\n",
    "            Data, Language, authorID,avg_nowords= get_data(dataFolder, xmlFile)\n",
    "            authorTextList.append(Data)\n",
    "            languageList.append(Language)\n",
    "            authorIDList.append(authorID)\n",
    "            avglist.append(avg_nowords)\n",
    "    return genderList, languageList, authorIDList, authorTextList, avglist#, httpList, atList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFoldertrain = 'Modeltr/'#folder where system model will be stored\n",
    "trainFolder = 'rusprofiling.training.20170629/'# the xml files have be saved with the ground label file labeled as \"truth.txt\"\n",
    "dataFolder = trainFolder\n",
    "genderList_train, languageList_train, authorIDList_train, authorTextList_train,avglist_train = load_data(dataFolder, 'TRAIN')\n",
    "tempTextList_train = [''.join(authorText) for authorText in authorTextList_train ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Calling Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFolder = 'Modelte/'#folder where system model will be stored\n",
    "#trainFolder = 'rusprofiling.training.20170629/'# the xml files have be saved with the ground label file labeled as \"truth.txt\"\n",
    "testFolder = 'rustesting corpus/rusprofiling.test.3.20170629'\n",
    "#dataFolder = trainFolder\n",
    "dataFolder = testFolder\n",
    "genderList_test, languageList_test, authorIDList_test, authorTextList_test,avglist_test= load_data(dataFolder, 'TEST')\n",
    "tempTextList_test = [''.join(authorText) for authorText in authorTextList_test ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing required library for feature extraction\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "    \n",
    "## function for creating document term matrix\n",
    "def get_tdm(data_samples,tdata, Language, Action, mini_df):\n",
    "    if Action == 'TRAIN':\n",
    "        tf_vectorizer = CountVectorizer(min_df = mini_df,ngram_range=(1,2))#,max_features = 30000)\n",
    "        print 'term document matrix'\n",
    "        print 'minimum document frequency', mini_df\n",
    "        tf_vectorizer.fit(data_samples)\n",
    "        dtMatrix = tf_vectorizer.transform(tdata)\n",
    "        #  dtMatrix = tf_vectorizer.transform(data_samples)\n",
    "    return dtMatrix\n",
    "\n",
    "## function for creating term frequency - inverse document frequency matrix\n",
    "def get_tdidf(data_samples,tdata, Language, Action, mini_df):\n",
    "    if Action == 'TRAIN':\n",
    "        print 'term document matrix'\n",
    "        print 'minimum document frequency', mini_df\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df = mini_df,ngram_range=(1,2),max_features = 20000)\n",
    "        tfidf_vectorizer = tfidf_vectorizer.fit(data_samples)\n",
    "        tfidfMatrix = tfidf_vectorizer.fit_transform(tdata)\n",
    "        return tfidfMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Tesing for TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "avglist_train_vec=(np.asarray(avglist_train)).reshape(-1,1)\n",
    "avglist_test_vec=(np.asarray(avglist_test)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term document matrix\n",
      "minimum document frequency 3\n"
     ]
    }
   ],
   "source": [
    "dtMatTrain_td = get_tdm(tempTextList_train+tempTextList_test,tempTextList_train,languageList_train[0],'TRAIN',3)\n",
    "dtMatTrain_td_1=dtMatTrain_td.todense()\n",
    "feat_vec_train =np.concatenate((dtMatTrain_td_1,avglist_train_vec),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 67891)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_vec_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term document matrix\n",
      "minimum document frequency 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((600, 67891), (400, 67891))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtMatTest_td = get_tdm(tempTextList_train+tempTextList_test,tempTextList_test,languageList_test[0],'TRAIN',3)\n",
    "dtMatTest_td_1=dtMatTest_td.todense()\n",
    "feat_vec_test = np.concatenate((dtMatTest_td_1,avglist_test_vec),axis = 1)\n",
    "feat_vec_train.shape, feat_vec_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Tesing for TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term document matrix\n",
      "minimum document frequency 3\n"
     ]
    }
   ],
   "source": [
    "dtMatTrain = get_tdidf(tempTextList_train+tempTextList_test,tempTextList_train,languageList_train[0],'TRAIN',3)\n",
    "dtMatTrain_1= dtMatTrain.todense()\n",
    "feat_vec_train_2 =np.concatenate((dtMatTrain_1,avglist_train_vec),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term document matrix\n",
      "minimum document frequency 3\n"
     ]
    }
   ],
   "source": [
    "dtMatTest = get_tdidf(tempTextList_train+tempTextList_test,tempTextList_test,languageList_test[0],'TRAIN',3)\n",
    "dtMatTest_1= dtMatTest.todense()\n",
    "feat_vec_test_2 =np.concatenate((dtMatTest_1,avglist_test_vec),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 20001), (400, 19833))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_vec_train_2.shape, feat_vec_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validation\n",
    "#from sklearn.decomposition import NMF\n",
    "\n",
    "def cv(Train_Mat , Target_label, classifier):\n",
    "    tot1 = 0\n",
    "    for i in range(1,11):\n",
    "        #print i\n",
    "        X_train,X_test,y_train,y_test = train_test_split(Train_Mat,Target_label,test_size=0.1,random_state=i)\n",
    "        if classifier == 'SVM':\n",
    "            clf_svm = svm.SVC(kernel = 'linear')\n",
    "            clf_svm.fit(X_train,y_train)\n",
    "            tot = clf_svm.score(X_test, y_test)\n",
    "            #print 'i:',i,'tot:',tot\n",
    "        if classifier == 'DT':\n",
    "            clf_DT = DecisionTreeClassifier()\n",
    "            clf_DT.fit(X_train,y_train)\n",
    "            tot = clf_DT.score(X_test, y_test)\n",
    "            #print 'i:',i,'tot:',tot\n",
    "            #tot1 = tot1+tot\n",
    "            #return (tot1/10)*100\n",
    "        if classifier == 'Ada':\n",
    "            clf_ada = AdaBoostClassifier(n_estimators=100)\n",
    "            clf_ada.fit(X_train,y_train)\n",
    "            tot = clf_ada.score(X_test, y_test)\n",
    "            #print 'i:',i,'tot:',tot\n",
    "            #tot1 = tot1+tot\n",
    "            #return (tot1/10)*100\n",
    "        if classifier == 'RF':\n",
    "            clf_RF = RandomForestClassifier(n_estimators=100)\n",
    "            clf_RF.fit(X_train,y_train)\n",
    "            tot = clf_RF.score(X_test, y_test)\n",
    "        if classifier == 'LR':\n",
    "            clf_LR = LogisticRegression(penalty='l2')\n",
    "            clf_LR.fit(X_train,y_train)\n",
    "            tot = clf_LR.score(X_test,y_test)\n",
    "            #print 'i:',i,'tot:',tot        \n",
    "        tot1 = tot1+tot\n",
    "    return (tot1/10.0)*100\n",
    "        #print tot\n",
    "        #tot1 = tot1+tot\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.833333333333329"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train,genderList_train,classifier='SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train_2,genderList_train,classifier='SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.499999999999986"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train,genderList_train,classifier='DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.166666666666657"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train_2,genderList_train,classifier='DT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.999999999999986"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train,genderList_train,classifier='Ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.166666666666671"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train_2,genderList_train,classifier=\"Ada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.333333333333329"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train,genderList_train,classifier='RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(feat_vec_train_2,genderList_train,classifier=\"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(dtMatTrain,genderList_train,classifier='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tSVD(Train_Mat,it):\n",
    "\t\tsvd = TruncatedSVD(n_components=it, n_iter=7, random_state=42)\n",
    "\t\tsvd.fit(Train_Mat)\n",
    "\t\tDT_tSVD = svd.transform(Train_Mat)\n",
    "\t\treturn DT_tSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 300)\n",
      "Avg accuracy_SVM : 79.0\n"
     ]
    }
   ],
   "source": [
    "####GRID SEARCH METHOD FOR FINDING N_COMPONENT\n",
    "\n",
    "#for it in range(100,500,50):\n",
    "#\tprint it\n",
    "it = 300\n",
    "DT_tSVD = tSVD(feat_vec_train_2,it)\n",
    "print (DT_tSVD).shape\n",
    "\n",
    "TD_SVD = cv(DT_tSVD , genderList_train,classifier='SVM')\n",
    "print 'Avg accuracy_SVM :',TD_SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy_DT : 56.0\n"
     ]
    }
   ],
   "source": [
    "TD_SVD_DT = cv(DT_tSVD , genderList_train,classifier='DT')\n",
    "print 'Avg accuracy_DT :',TD_SVD_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy_SVM_Ada : 71.5\n"
     ]
    }
   ],
   "source": [
    "TD_SVD_Ada = cv(DT_tSVD , genderList_train,classifier='Ada')\n",
    "print 'Avg accuracy_SVM_Ada :',TD_SVD_Ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy_RF : 72.1666666667\n"
     ]
    }
   ],
   "source": [
    "TD_SVD_RF = cv(DT_tSVD , genderList_train,classifier='RF')\n",
    "print 'Avg accuracy_RF :',TD_SVD_RF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
